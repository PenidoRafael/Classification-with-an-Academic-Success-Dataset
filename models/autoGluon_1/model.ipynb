{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c0db9bfa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-19T00:53:25.163655Z",
     "iopub.status.busy": "2024-06-19T00:53:25.163258Z",
     "iopub.status.idle": "2024-06-19T01:03:42.753353Z",
     "shell.execute_reply": "2024-06-19T01:03:42.751564Z"
    },
    "papermill": {
     "duration": 617.598344,
     "end_time": "2024-06-19T01:03:42.756548",
     "exception": false,
     "start_time": "2024-06-19T00:53:25.158204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd3fc122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "SEED = 42 # Muito importante manter a SEED igual em todos os modelos para garantir a consistência dos dados no ensemble\n",
    "FOLDS = 5 # Muito importante manter o mesmo número de FOLDS em todos os modelos para garantir a consistência dos dados no ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "857c1eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T01:04:13.869823Z",
     "iopub.status.busy": "2024-06-19T01:04:13.869402Z",
     "iopub.status.idle": "2024-06-19T01:04:13.875182Z",
     "shell.execute_reply": "2024-06-19T01:04:13.874042Z"
    },
    "papermill": {
     "duration": 0.461416,
     "end_time": "2024-06-19T01:04:13.877634",
     "exception": false,
     "start_time": "2024-06-19T01:04:13.416218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = \"Target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "82cf291c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T01:04:16.525061Z",
     "iopub.status.busy": "2024-06-19T01:04:16.523872Z",
     "iopub.status.idle": "2024-06-19T01:04:17.258629Z",
     "shell.execute_reply": "2024-06-19T01:04:17.257147Z"
    },
    "papermill": {
     "duration": 1.219607,
     "end_time": "2024-06-19T01:04:17.261568",
     "exception": false,
     "start_time": "2024-06-19T01:04:16.041961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sintetico = pd.read_csv('../../src/train/train.csv', index_col='id')\n",
    "original = pd.read_csv('../../src/train/original.csv')\n",
    "test = pd.read_csv('../../src/test/test.csv', index_col='id')\n",
    "\n",
    "train = pd.concat([sintetico, original], ignore_index=True)\n",
    "\n",
    "initial_features = list(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1380e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(label, X, y, encoder, hyperparameters, scoring=accuracy_score):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    scores = []\n",
    "    out_of_fold = []\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {i + 1}\")\n",
    "\n",
    "        model = TabularPredictor(label=label)\n",
    "        \n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        train_fold = pd.concat([X_train, y_train.rename('Target')], axis=1)\n",
    "        \n",
    "        X_val = X.iloc[val_index]\n",
    "        y_val = y.iloc[val_index]\n",
    "        val_fold = pd.concat([X_val, y_val.rename('Target')], axis=1)\n",
    "\n",
    "        train_data = TabularDataset(train_fold)\n",
    "        val_data = TabularDataset(val_fold)\n",
    "\n",
    "        model.fit(\n",
    "                train_data,\n",
    "                presets='best_quality',\n",
    "                time_limit=3600*1.5, \n",
    "                hyperparameters=hyperparameters\n",
    "            )\n",
    "\n",
    "        probabilidades = model.predict_proba(val_data)\n",
    "\n",
    "        # Recuperar a predição final a partir das probabilidades\n",
    "        indices_predicoes = np.argmax(probabilidades, axis=1)\n",
    "        classes_preditas = np.array(model.classes_)[indices_predicoes]\n",
    "        \n",
    "        score = scoring(y_val, classes_preditas)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        true_label = pd.Series(y_val.values, name='true').reset_index(drop=True)\n",
    "        pred_label_df = pd.DataFrame(probabilidades).reset_index(drop=True)\n",
    "\n",
    "        oof_pred = pd.concat([pred_label_df, true_label], axis=1, ignore_index=True)\n",
    "        oof_pred.columns = [f'pred_{encoder[model.classes_[0]]}', f'pred_{encoder[model.classes_[1]]}', f'pred_{encoder[model.classes_[2]]}', 'true']\n",
    "\n",
    "        print(oof_pred.shape)\n",
    "        out_of_fold.append(oof_pred)\n",
    "\n",
    "    print(f\"Score: {np.mean(scores)}\")\n",
    "    \n",
    "    return scores, out_of_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e596613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_oof(oof):\n",
    "\n",
    "    os.makedirs('oof', exist_ok=True)\n",
    "\n",
    "    for i, fold in enumerate(oof):\n",
    "        fold.to_csv(f'oof/fold_{i+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "163dbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(target, X_train, y_train, X_test, encoder, hyperparameters):\n",
    "\n",
    "    train_fold = pd.concat([X_train, y_train.rename('Target')], axis=1)\n",
    "\n",
    "    model = TabularPredictor(label=target)\n",
    "\n",
    "    train_data = TabularDataset(train_fold)\n",
    "    test_data  = TabularDataset(X_test)\n",
    "\n",
    "    model.fit(\n",
    "            train_data,\n",
    "            presets='best_quality',\n",
    "            time_limit=3600*2, \n",
    "            hyperparameters=hyperparameters\n",
    "        )\n",
    "\n",
    "    probabilidades = model.predict_proba(test_data)\n",
    "    pred_label_df = pd.DataFrame(probabilidades)\n",
    "\n",
    "    pred_label_df.columns = [f'pred_{encoder[model.classes_[0]]}', f'pred_{encoder[model.classes_[1]]}', f'pred_{encoder[model.classes_[2]]}']\n",
    "\n",
    "    os.makedirs('test', exist_ok=True)\n",
    "\n",
    "    pred_label_df.to_csv(f'test/test_pred.csv', index=False)\n",
    "\n",
    "    return pred_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a98be4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.pop('Target')\n",
    "X = train\n",
    "\n",
    "initial_features = list(X.columns)\n",
    "\n",
    "encoder = {\n",
    "        'Graduate':'Graduate',\n",
    "        'Enrolled':'Enrolled',\n",
    "        'Dropout':'Dropout'\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a056598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T01:04:18.244895Z",
     "iopub.status.busy": "2024-06-19T01:04:18.243816Z",
     "iopub.status.idle": "2024-06-19T03:54:58.830568Z",
     "shell.execute_reply": "2024-06-19T03:54:58.829191Z"
    },
    "papermill": {
     "duration": 10241.10961,
     "end_time": "2024-06-19T03:54:58.833881",
     "exception": false,
     "start_time": "2024-06-19T01:04:17.724271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'NN_TORCH': {},\n",
    "    'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
    "    'CAT': {},\n",
    "    'XGB': {},\n",
    "    'FASTAI': {},\n",
    "    'RF': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
    "    'XT': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
    "    'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "466bd5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240622_013857\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue May  7 09:00:52 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       7.60 GB / 22.84 GB (33.3%)\n",
      "Disk Space Avail:   13.79 GB / 95.56 GB (14.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1350s of the 5400.0s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240622_013857/ds_sub_fit/sub_fit_ho\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0        LightGBMXT_BAG_L2       0.827797   0.831318    accuracy        5.599851      38.199768  538.495377                 0.112821                0.341934           9.251419            2       True         12\n",
      "1     LightGBMLarge_BAG_L2       0.827241   0.831596    accuracy        5.766252      38.736983  549.000515                 0.279222                0.879149          19.756557            2       True         17\n",
      "2      WeightedEnsemble_L3       0.827241   0.832274    accuracy        6.620630      40.249900  689.869828                 0.002578                0.004351           1.650802            3       True         18\n",
      "3   NeuralNetFastAI_BAG_L2       0.827102   0.831526    accuracy        6.267866      39.387248  648.300016                 0.780836                1.529414         119.056058            2       True         11\n",
      "4           XGBoost_BAG_L2       0.826963   0.831631    accuracy        5.724395      38.374201  559.911549                 0.237365                0.516367          30.667591            2       True         15\n",
      "5        LightGBMXT_BAG_L1       0.826824   0.830154    accuracy        1.147054      16.981488   60.912591                 1.147054               16.981488          60.912591            1       True          4\n",
      "6          LightGBM_BAG_L2       0.826824   0.831544    accuracy        5.588625      38.153209  540.695914                 0.101595                0.295375          11.451956            2       True         13\n",
      "7          CatBoost_BAG_L2       0.826407   0.831266    accuracy        5.565052      37.950950  543.724522                 0.078022                0.093116          14.480563            2       True         14\n",
      "8           XGBoost_BAG_L1       0.826129   0.831318    accuracy        0.532717       3.121972   33.153204                 0.532717                3.121972          33.153204            1       True          7\n",
      "9      WeightedEnsemble_L2       0.826129   0.831318    accuracy        0.534117       3.130885   35.524298                 0.001399                0.008913           2.371094            2       True         10\n",
      "10   NeuralNetTorch_BAG_L2       0.825990   0.831266    accuracy        5.920281      38.777269  677.836521                 0.433251                0.919435         148.592563            2       True         16\n",
      "11         CatBoost_BAG_L1       0.825712   0.829633    accuracy        0.351545       0.252368  122.360270                 0.351545                0.252368         122.360270            1       True          6\n",
      "12    LightGBMLarge_BAG_L1       0.825712   0.830050    accuracy        0.830344       7.967016   31.665477                 0.830344                7.967016          31.665477            1       True          9\n",
      "13         LightGBM_BAG_L1       0.825573   0.830814    accuracy        0.480114       2.232444   34.034046                 0.480114                2.232444          34.034046            1       True          5\n",
      "14  NeuralNetFastAI_BAG_L1       0.817790   0.823152    accuracy        1.145244       1.657346  125.334221                 1.145244                1.657346         125.334221            1       True          3\n",
      "15   NeuralNetTorch_BAG_L1       0.816400   0.821745    accuracy        0.283313       0.660571  121.668144                 0.283313                0.660571         121.668144            1       True          8\n",
      "16   KNeighborsDist_BAG_L1       0.726616   0.731158    accuracy        0.357608       2.347403    0.058532                 0.357608                2.347403           0.058532            1       True          2\n",
      "17   KNeighborsUnif_BAG_L1       0.725643   0.728205    accuracy        0.359090       2.637227    0.057473                 0.359090                2.637227           0.057473            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t1206s\t = DyStack   runtime |\t4194s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 4194s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240622_013857\"\n",
      "Train Data Rows:    64753\n",
      "Train Data Columns: 36\n",
      "Label Column:       Target\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11138.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 17.79 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])   : 29 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Daytime/evening attendance', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])       : 21 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Previous qualification', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t36 features in original data used to generate 36 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 14.33 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'XT': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2794.92s of the 4193.43s of remaining time.\n",
      "\t0.7295\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.82s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2790.95s of the 4189.46s of remaining time.\n",
      "\t0.7318\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2787.42s of the 4185.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.42%)\n",
      "\t0.8236\t = Validation score   (accuracy)\n",
      "\t102.44s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2682.89s of the 4081.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.07%)\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t22.04s\t = Training   runtime\n",
      "\t12.27s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2656.6s of the 4055.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.94%)\n",
      "\t0.8311\t = Validation score   (accuracy)\n",
      "\t11.56s\t = Training   runtime\n",
      "\t2.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2642.73s of the 4041.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.00%)\n",
      "\t0.831\t = Validation score   (accuracy)\n",
      "\t92.91s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2547.85s of the 3946.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.27%)\n",
      "\t0.8305\t = Validation score   (accuracy)\n",
      "\t16.08s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2529.56s of the 3928.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.79%)\n",
      "\t0.8218\t = Validation score   (accuracy)\n",
      "\t157.48s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2370.17s of the 3768.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.17%)\n",
      "\t0.8304\t = Validation score   (accuracy)\n",
      "\t19.47s\t = Training   runtime\n",
      "\t4.83s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 3745.66s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 3744.34s of the 3744.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.05%)\n",
      "\t0.8313\t = Validation score   (accuracy)\n",
      "\t107.96s\t = Training   runtime\n",
      "\t1.24s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 3634.26s of the 3634.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.41%)\n",
      "\t0.8308\t = Validation score   (accuracy)\n",
      "\t7.18s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3624.88s of the 3624.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.40%)\n",
      "\t0.8323\t = Validation score   (accuracy)\n",
      "\t11.26s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 3611.09s of the 3611.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.49%)\n",
      "\t0.8309\t = Validation score   (accuracy)\n",
      "\t10.31s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 3598.78s of the 3598.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.87%)\n",
      "\t0.8317\t = Validation score   (accuracy)\n",
      "\t10.4s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 3586.32s of the 3586.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.15%)\n",
      "\t0.8314\t = Validation score   (accuracy)\n",
      "\t120.88s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 3463.23s of the 3463.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.73%)\n",
      "\t0.8313\t = Validation score   (accuracy)\n",
      "\t16.45s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 374.43s of the 3444.25s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 1.0}\n",
      "\t0.8323\t = Validation score   (accuracy)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 751.61s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 334.9 rows/s (8095 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240622_013857\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240622_021147\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue May  7 09:00:52 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       11.30 GB / 22.84 GB (49.5%)\n",
      "Disk Space Avail:   13.54 GB / 95.56 GB (14.2%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1350s of the 5400.0s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240622_021147/ds_sub_fit/sub_fit_ho\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16189, 4)\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0          LightGBM_BAG_L2       0.831967   0.830137    accuracy        4.773469      15.406202  334.043512                 0.128734                0.359432           8.550268            2       True         13\n",
      "1     LightGBMLarge_BAG_L2       0.831411   0.830328    accuracy        4.867823      15.691530  344.654612                 0.223087                0.644760          19.161367            2       True         17\n",
      "2   NeuralNetFastAI_BAG_L2       0.830855   0.830241    accuracy        5.400217      16.326406  419.707553                 0.755481                1.279636          94.214308            2       True         11\n",
      "3           XGBoost_BAG_L1       0.830716   0.830571    accuracy        0.486028       1.466990   13.304776                 0.486028                1.466990          13.304776            1       True          7\n",
      "4      WeightedEnsemble_L2       0.830716   0.830571    accuracy        0.487450       1.471585   14.340945                 0.001422                0.004594           1.036169            2       True         10\n",
      "5      WeightedEnsemble_L3       0.830716   0.830571    accuracy        0.487515       1.471381   15.033766                 0.001487                0.004390           1.728991            3       True         18\n",
      "6        LightGBMXT_BAG_L2       0.830021   0.830206    accuracy        4.791876      15.465188  334.072026                 0.147141                0.418418           8.578782            2       True         12\n",
      "7    NeuralNetTorch_BAG_L2       0.829048   0.830032    accuracy        5.071165      15.821674  433.844399                 0.426430                0.774904         108.351155            2       True         16\n",
      "8           XGBoost_BAG_L2       0.828770   0.830223    accuracy        4.868481      15.449910  335.065730                 0.223746                0.403140           9.572486            2       True         15\n",
      "9          LightGBM_BAG_L1       0.828631   0.829528    accuracy        0.441791       1.766322    8.277941                 0.441791                1.766322           8.277941            1       True          5\n",
      "10    LightGBMLarge_BAG_L1       0.828075   0.828834    accuracy        0.695251       2.381458   14.253153                 0.695251                2.381458          14.253153            1       True          9\n",
      "11         CatBoost_BAG_L2       0.828075   0.830432    accuracy        4.712841      15.134351  338.053319                 0.068106                0.087581          12.560075            2       True         14\n",
      "12       LightGBMXT_BAG_L1       0.827241   0.828382    accuracy        0.649923       2.494909   13.155402                 0.649923                2.494909          13.155402            1       True          4\n",
      "13         CatBoost_BAG_L1       0.826685   0.828747    accuracy        0.265772       0.114750   45.244062                 0.265772                0.114750          45.244062            1       True          6\n",
      "14  NeuralNetFastAI_BAG_L1       0.820987   0.822944    accuracy        1.140583       1.012928   91.526067                 1.140583                1.012928          91.526067            1       True          3\n",
      "15   NeuralNetTorch_BAG_L1       0.819041   0.821780    accuracy        0.277528       0.486021  139.638391                 0.277528                0.486021         139.638391            1       True          8\n",
      "16   KNeighborsDist_BAG_L1       0.734399   0.729230    accuracy        0.320000       2.617372    0.044622                 0.320000                2.617372           0.044622            1       True          2\n",
      "17   KNeighborsUnif_BAG_L1       0.732036   0.727249    accuracy        0.367859       2.706020    0.048830                 0.367859                2.706020           0.048830            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t635s\t = DyStack   runtime |\t4765s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 4765s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240622_021147\"\n",
      "Train Data Rows:    64753\n",
      "Train Data Columns: 36\n",
      "Label Column:       Target\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11163.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 17.79 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])   : 29 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Daytime/evening attendance', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])       : 21 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Previous qualification', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t36 features in original data used to generate 36 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 14.33 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'XT': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3175.48s of the 4764.41s of remaining time.\n",
      "\t0.7281\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.25s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3172.07s of the 4761.0s of remaining time.\n",
      "\t0.7315\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3168.87s of the 4757.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.42%)\n",
      "\t0.8221\t = Validation score   (accuracy)\n",
      "\t105.5s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3061.21s of the 4650.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.04%)\n",
      "\t0.8305\t = Validation score   (accuracy)\n",
      "\t22.43s\t = Training   runtime\n",
      "\t8.73s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3034.55s of the 4623.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.95%)\n",
      "\t0.8308\t = Validation score   (accuracy)\n",
      "\t14.3s\t = Training   runtime\n",
      "\t2.41s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3017.54s of the 4606.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.01%)\n",
      "\t0.829\t = Validation score   (accuracy)\n",
      "\t86.86s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2928.7s of the 4517.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.27%)\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t16.65s\t = Training   runtime\n",
      "\t1.67s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2909.91s of the 4498.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.79%)\n",
      "\t0.8221\t = Validation score   (accuracy)\n",
      "\t152.38s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2755.37s of the 4344.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.15%)\n",
      "\t0.8301\t = Validation score   (accuracy)\n",
      "\t20.06s\t = Training   runtime\n",
      "\t5.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 4320.54s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 4319.23s of the 4319.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.08%)\n",
      "\t0.831\t = Validation score   (accuracy)\n",
      "\t104.11s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4212.94s of the 4212.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.57%)\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t11.37s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 4199.15s of the 4199.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.40%)\n",
      "\t0.8308\t = Validation score   (accuracy)\n",
      "\t7.78s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4189.17s of the 4189.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.52%)\n",
      "\t0.8307\t = Validation score   (accuracy)\n",
      "\t16.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 4171.01s of the 4170.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.89%)\n",
      "\t0.8307\t = Validation score   (accuracy)\n",
      "\t8.94s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 4159.93s of the 4159.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.16%)\n",
      "\t0.831\t = Validation score   (accuracy)\n",
      "\t133.27s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 4024.44s of the 4024.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.75%)\n",
      "\t0.8301\t = Validation score   (accuracy)\n",
      "\t16.04s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 431.92s of the 4005.92s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 760.87s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 376.1 rows/s (8095 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240622_021147\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240622_023517\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue May  7 09:00:52 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       11.23 GB / 22.84 GB (49.2%)\n",
      "Disk Space Avail:   13.19 GB / 95.56 GB (13.8%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1350s of the 5400.0s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240622_023517/ds_sub_fit/sub_fit_ho\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16189, 4)\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     LightGBMLarge_BAG_L2       0.828214   0.831373    accuracy        4.982735      15.328460  373.272161                 0.248788                0.802093          23.528622            2       True         17\n",
      "1    NeuralNetTorch_BAG_L2       0.828214   0.831634    accuracy        5.190775      15.251335  459.357677                 0.456828                0.724968         109.614138            2       True         16\n",
      "2   NeuralNetFastAI_BAG_L2       0.827658   0.831894    accuracy        5.540198      15.588882  445.354517                 0.806250                1.062515          95.610978            2       True         11\n",
      "3        LightGBMXT_BAG_L2       0.827519   0.832051    accuracy        4.878831      14.940564  357.937488                 0.144884                0.414197           8.193949            2       True         12\n",
      "4          LightGBM_BAG_L2       0.827380   0.831807    accuracy        4.848794      14.845652  357.906225                 0.114846                0.319285           8.162687            2       True         13\n",
      "5           XGBoost_BAG_L2       0.827380   0.832294    accuracy        4.982054      14.984971  359.500808                 0.248106                0.458604           9.757269            2       True         15\n",
      "6      WeightedEnsemble_L3       0.827380   0.832294    accuracy        4.983466      14.989492  361.146336                 0.001412                0.004521           1.645528            3       True         18\n",
      "7     LightGBMLarge_BAG_L1       0.826546   0.830400    accuracy        0.564032       2.161510   14.030919                 0.564032                2.161510          14.030919            1       True          9\n",
      "8          CatBoost_BAG_L2       0.826546   0.831582    accuracy        4.822726      14.641213  366.795534                 0.088778                0.114846          17.051995            2       True         14\n",
      "9          CatBoost_BAG_L1       0.826129   0.829879    accuracy        0.300193       0.139765   75.538335                 0.300193                0.139765          75.538335            1       True          6\n",
      "10          XGBoost_BAG_L1       0.825990   0.831773    accuracy        0.434298       1.444494   14.048522                 0.434298                1.444494          14.048522            1       True          7\n",
      "11     WeightedEnsemble_L2       0.825990   0.831773    accuracy        0.435694       1.449241   15.121196                 0.001396                0.004746           1.072675            2       True         10\n",
      "12         LightGBM_BAG_L1       0.824461   0.831408    accuracy        0.417232       1.228573    8.713902                 0.417232                1.228573           8.713902            1       True          5\n",
      "13       LightGBMXT_BAG_L1       0.824461   0.829479    accuracy        0.817348       2.732983   13.545949                 0.817348                2.732983          13.545949            1       True          4\n",
      "14  NeuralNetFastAI_BAG_L1       0.819180   0.823381    accuracy        1.091686       1.021190   95.197377                 1.091686                1.021190          95.197377            1       True          3\n",
      "15   NeuralNetTorch_BAG_L1       0.818624   0.822374    accuracy        0.274301       0.503326  128.577801                 0.274301                0.503326         128.577801            1       True          8\n",
      "16   KNeighborsDist_BAG_L1       0.726894   0.734377    accuracy        0.308727       2.673783    0.042224                 0.308727                2.673783           0.042224            1       True          2\n",
      "17   KNeighborsUnif_BAG_L1       0.722446   0.730624    accuracy        0.526131       2.620743    0.048512                 0.526131                2.620743           0.048512            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t671s\t = DyStack   runtime |\t4729s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 4729s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240622_023517\"\n",
      "Train Data Rows:    64754\n",
      "Train Data Columns: 36\n",
      "Label Column:       Target\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11120.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 17.79 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])   : 29 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Daytime/evening attendance', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])       : 21 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Previous qualification', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t36 features in original data used to generate 36 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 14.33 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'XT': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3152.03s of the 4729.22s of remaining time.\n",
      "\t0.7312\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t3.35s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3148.52s of the 4725.72s of remaining time.\n",
      "\t0.7346\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3145.22s of the 4722.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.42%)\n",
      "\t0.8228\t = Validation score   (accuracy)\n",
      "\t105.78s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3037.3s of the 4614.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.01%)\n",
      "\t0.8304\t = Validation score   (accuracy)\n",
      "\t16.21s\t = Training   runtime\n",
      "\t5.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3017.66s of the 4594.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.96%)\n",
      "\t0.832\t = Validation score   (accuracy)\n",
      "\t14.77s\t = Training   runtime\n",
      "\t2.97s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3000.1s of the 4577.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.01%)\n",
      "\t0.8303\t = Validation score   (accuracy)\n",
      "\t70.72s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2927.44s of the 4504.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.27%)\n",
      "\t0.8314\t = Validation score   (accuracy)\n",
      "\t14.4s\t = Training   runtime\n",
      "\t1.37s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2910.86s of the 4488.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.80%)\n",
      "\t0.8224\t = Validation score   (accuracy)\n",
      "\t149.77s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2759.06s of the 4336.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.15%)\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t16.88s\t = Training   runtime\n",
      "\t4.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 4316.11s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.832\t = Validation score   (accuracy)\n",
      "\t1.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 4314.84s of the 4314.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.06%)\n",
      "\t0.8323\t = Validation score   (accuracy)\n",
      "\t108.15s\t = Training   runtime\n",
      "\t1.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4204.5s of the 4204.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.44%)\n",
      "\t0.8321\t = Validation score   (accuracy)\n",
      "\t9.14s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 4193.08s of the 4193.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.40%)\n",
      "\t0.8326\t = Validation score   (accuracy)\n",
      "\t9.47s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4181.46s of the 4181.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.51%)\n",
      "\t0.8316\t = Validation score   (accuracy)\n",
      "\t19.99s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 4159.33s of the 4159.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.88%)\n",
      "\t0.8322\t = Validation score   (accuracy)\n",
      "\t10.62s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 4146.47s of the 4146.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.18%)\n",
      "\t0.8321\t = Validation score   (accuracy)\n",
      "\t118.83s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 4025.52s of the 4025.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.74%)\n",
      "\t0.8323\t = Validation score   (accuracy)\n",
      "\t20.32s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 431.48s of the 4002.69s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 1.0}\n",
      "\t0.8326\t = Validation score   (accuracy)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 728.98s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 481.6 rows/s (8095 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240622_023517\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240622_025847\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue May  7 09:00:52 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       11.14 GB / 22.84 GB (48.8%)\n",
      "Disk Space Avail:   12.87 GB / 95.56 GB (13.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1350s of the 5400.0s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240622_025847/ds_sub_fit/sub_fit_ho\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16188, 4)\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           XGBoost_BAG_L2       0.837248   0.830748    accuracy        5.822788      20.249507  373.260993                 0.214089                0.485047          12.073379            2       True         15\n",
      "1          LightGBM_BAG_L2       0.836414   0.830626    accuracy        5.728186      20.099093  370.288321                 0.119487                0.334633           9.100708            2       True         13\n",
      "2     LightGBMLarge_BAG_L1       0.836136   0.829879    accuracy        0.762292       4.263760   18.820672                 0.762292                4.263760          18.820672            1       True          9\n",
      "3          LightGBM_BAG_L1       0.835997   0.830018    accuracy        0.526825       1.662234   11.006286                 0.526825                1.662234          11.006286            1       True          5\n",
      "4     LightGBMLarge_BAG_L2       0.835858   0.829827    accuracy        5.781930      20.370034  380.126732                 0.173231                0.605574          18.939118            2       True         17\n",
      "5        LightGBMXT_BAG_L2       0.835858   0.830730    accuracy        5.789259      20.303630  372.431659                 0.180561                0.539169          11.244045            2       True         12\n",
      "6    NeuralNetTorch_BAG_L2       0.835858   0.830470    accuracy        6.050154      20.512098  470.629916                 0.441455                0.747638         109.442302            2       True         16\n",
      "7          CatBoost_BAG_L1       0.835719   0.829688    accuracy        0.294523       0.172857   78.028294                 0.294523                0.172857          78.028294            1       True          6\n",
      "8   NeuralNetFastAI_BAG_L2       0.834885   0.830226    accuracy        6.502946      20.859921  451.620324                 0.894247                1.095461          90.432710            2       True         11\n",
      "9      WeightedEnsemble_L3       0.834051   0.830852    accuracy        5.824743      20.254037  374.910527                 0.001955                0.004530           1.649534            3       True         18\n",
      "10          XGBoost_BAG_L1       0.833912   0.830800    accuracy        0.492845       1.765797   14.346370                 0.492845                1.765797          14.346370            1       True          7\n",
      "11     WeightedEnsemble_L2       0.833912   0.830800    accuracy        0.494279       1.770406   15.418542                 0.001434                0.004609           1.072172            2       True         10\n",
      "12       LightGBMXT_BAG_L1       0.833912   0.828854    accuracy        1.289205       5.035074   19.017645                 1.289205                5.035074          19.017645            1       True          4\n",
      "13         CatBoost_BAG_L2       0.833773   0.830435    accuracy        5.682795      19.865667  375.725274                 0.074096                0.101206          14.537660            2       True         14\n",
      "14  NeuralNetFastAI_BAG_L1       0.828214   0.822235    accuracy        1.088555       1.073491   94.827810                 1.088555                1.073491          94.827810            1       True          3\n",
      "15   NeuralNetTorch_BAG_L1       0.827936   0.820758    accuracy        0.294459       0.462437  125.049594                 0.294459                0.462437         125.049594            1       True          8\n",
      "16   KNeighborsDist_BAG_L1       0.736762   0.730850    accuracy        0.396085       2.751461    0.042885                 0.396085                2.751461           0.042885            1       True          2\n",
      "17   KNeighborsUnif_BAG_L1       0.732870   0.728192    accuracy        0.463912       2.577351    0.048059                 0.463912                2.577351           0.048059            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t678s\t = DyStack   runtime |\t4722s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 4722s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240622_025847\"\n",
      "Train Data Rows:    64754\n",
      "Train Data Columns: 36\n",
      "Label Column:       Target\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11082.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 17.79 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])   : 29 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Daytime/evening attendance', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])       : 21 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Previous qualification', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t36 features in original data used to generate 36 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 14.33 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'XT': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3146.86s of the 4721.48s of remaining time.\n",
      "\t0.7299\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.35s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3143.36s of the 4717.97s of remaining time.\n",
      "\t0.7329\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3139.98s of the 4714.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.43%)\n",
      "\t0.8226\t = Validation score   (accuracy)\n",
      "\t107.5s\t = Training   runtime\n",
      "\t1.14s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3030.41s of the 4605.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.98%)\n",
      "\t0.8299\t = Validation score   (accuracy)\n",
      "\t17.33s\t = Training   runtime\n",
      "\t3.59s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3010.03s of the 4584.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.95%)\n",
      "\t0.8305\t = Validation score   (accuracy)\n",
      "\t10.97s\t = Training   runtime\n",
      "\t2.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2996.64s of the 4571.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.01%)\n",
      "\t0.8285\t = Validation score   (accuracy)\n",
      "\t60.51s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2934.07s of the 4508.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.27%)\n",
      "\t0.8309\t = Validation score   (accuracy)\n",
      "\t15.64s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2916.2s of the 4490.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.80%)\n",
      "\t0.8217\t = Validation score   (accuracy)\n",
      "\t175.06s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2739.22s of the 4313.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.15%)\n",
      "\t0.8302\t = Validation score   (accuracy)\n",
      "\t15.05s\t = Training   runtime\n",
      "\t2.68s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 4295.96s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.8309\t = Validation score   (accuracy)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 4294.66s of the 4294.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.06%)\n",
      "\t0.8314\t = Validation score   (accuracy)\n",
      "\t108.34s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4184.2s of the 4184.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.50%)\n",
      "\t0.8309\t = Validation score   (accuracy)\n",
      "\t9.58s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 4172.18s of the 4172.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.40%)\n",
      "\t0.8313\t = Validation score   (accuracy)\n",
      "\t8.65s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4161.31s of the 4161.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.53%)\n",
      "\t0.8308\t = Validation score   (accuracy)\n",
      "\t12.12s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 4146.98s of the 4146.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.88%)\n",
      "\t0.8311\t = Validation score   (accuracy)\n",
      "\t11.75s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 4133.12s of the 4133.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.16%)\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t109.76s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 4021.16s of the 4021.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.74%)\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t18.6s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 429.47s of the 4000.1s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.391, 'NeuralNetTorch_BAG_L2': 0.261, 'LightGBM_BAG_L2': 0.13, 'XGBoost_BAG_L2': 0.13, 'XGBoost_BAG_L1': 0.043, 'LightGBMLarge_BAG_L1': 0.043}\n",
      "\t0.832\t = Validation score   (accuracy)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 723.75s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 529.5 rows/s (8095 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240622_025847\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240622_032222\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue May  7 09:00:52 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       11.16 GB / 22.84 GB (48.9%)\n",
      "Disk Space Avail:   12.69 GB / 95.56 GB (13.3%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1350s of the 5400.0s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240622_032222/ds_sub_fit/sub_fit_ho\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16188, 4)\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0        LightGBMXT_BAG_L2       0.835719   0.829914    accuracy        5.837531      20.933567  382.825358                 0.164621                0.448862           8.111563            2       True         12\n",
      "1   NeuralNetFastAI_BAG_L2       0.835719   0.829723    accuracy        6.574782      21.565141  474.223644                 0.901872                1.080436          99.509849            2       True         11\n",
      "2          LightGBM_BAG_L2       0.835302   0.830487    accuracy        5.777387      20.754549  381.757032                 0.104476                0.269843           7.043237            2       True         13\n",
      "3      WeightedEnsemble_L3       0.835302   0.830487    accuracy        5.778923      20.759094  383.430094                 0.001537                0.004546           1.673063            3       True         18\n",
      "4           XGBoost_BAG_L1       0.835024   0.829132    accuracy        0.353475       1.162213   12.617124                 0.353475                1.162213          12.617124            1       True          7\n",
      "5           XGBoost_BAG_L2       0.835024   0.830348    accuracy        5.866133      20.858375  383.038773                 0.193223                0.373669           8.324978            2       True         15\n",
      "6        LightGBMXT_BAG_L1       0.834746   0.829097    accuracy        1.554600       8.210233   19.944934                 1.554600                8.210233          19.944934            1       True          4\n",
      "7     LightGBMLarge_BAG_L2       0.834746   0.829966    accuracy        5.937899      21.327842  393.765362                 0.264989                0.843137          19.051567            2       True         17\n",
      "8          CatBoost_BAG_L2       0.834607   0.829149    accuracy        5.769564      20.613807  390.461271                 0.096654                0.129102          15.747476            2       True         14\n",
      "9    NeuralNetTorch_BAG_L2       0.834607   0.829740    accuracy        6.130526      21.213605  471.830931                 0.457615                0.728900          97.117136            2       True         16\n",
      "10    LightGBMLarge_BAG_L1       0.833773   0.827777    accuracy        0.543749       2.200190   14.244138                 0.543749                2.200190          14.244138            1       True          9\n",
      "11         LightGBM_BAG_L1       0.833356   0.829670    accuracy        0.632163       1.688510   12.080491                 0.632163                1.688510          12.080491            1       True          5\n",
      "12     WeightedEnsemble_L2       0.833356   0.829670    accuracy        0.633618       1.693078   13.147194                 0.001455                0.004568           1.066703            2       True         10\n",
      "13         CatBoost_BAG_L1       0.833218   0.826943    accuracy        0.276735       0.132542   82.721574                 0.276735                0.132542          82.721574            1       True          6\n",
      "14  NeuralNetFastAI_BAG_L1       0.829048   0.821401    accuracy        1.142924       1.088279   97.248954                 1.142924                1.088279          97.248954            1       True          3\n",
      "15   NeuralNetTorch_BAG_L1       0.823350   0.820323    accuracy        0.279470       0.499934  135.758725                 0.279470                0.499934         135.758725            1       True          8\n",
      "16   KNeighborsDist_BAG_L1       0.735650   0.730728    accuracy        0.460461       2.887872    0.047513                 0.460461                2.887872           0.047513            1       True          2\n",
      "17   KNeighborsUnif_BAG_L1       0.735094   0.727914    accuracy        0.429333       2.614933    0.050342                 0.429333                2.614933           0.050342            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t681s\t = DyStack   runtime |\t4719s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 4719s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240622_032222\"\n",
      "Train Data Rows:    64754\n",
      "Train Data Columns: 36\n",
      "Label Column:       Target\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11452.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 17.79 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])   : 29 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Daytime/evening attendance', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])       : 21 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Previous qualification', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t36 features in original data used to generate 36 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 14.33 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'XT': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3144.82s of the 4718.41s of remaining time.\n",
      "\t0.731\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t3.28s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3141.4s of the 4714.99s of remaining time.\n",
      "\t0.7337\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3138.07s of the 4711.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.39%)\n",
      "\t0.8219\t = Validation score   (accuracy)\n",
      "\t106.84s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3029.06s of the 4602.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.94%)\n",
      "\t0.8295\t = Validation score   (accuracy)\n",
      "\t30.5s\t = Training   runtime\n",
      "\t9.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2992.78s of the 4566.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.93%)\n",
      "\t0.8304\t = Validation score   (accuracy)\n",
      "\t13.46s\t = Training   runtime\n",
      "\t2.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2976.58s of the 4550.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.99%)\n",
      "\t0.8287\t = Validation score   (accuracy)\n",
      "\t52.36s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2922.21s of the 4495.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.24%)\n",
      "\t0.8311\t = Validation score   (accuracy)\n",
      "\t16.22s\t = Training   runtime\n",
      "\t1.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2903.62s of the 4477.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.78%)\n",
      "\t0.8212\t = Validation score   (accuracy)\n",
      "\t157.0s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 2744.67s of the 4318.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.13%)\n",
      "\t0.8292\t = Validation score   (accuracy)\n",
      "\t14.12s\t = Training   runtime\n",
      "\t3.48s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 4301.27s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.8311\t = Validation score   (accuracy)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 4299.97s of the 4299.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.00%)\n",
      "\t0.8301\t = Validation score   (accuracy)\n",
      "\t106.13s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4191.47s of the 4191.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.40%)\n",
      "\t0.8311\t = Validation score   (accuracy)\n",
      "\t8.45s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 4180.82s of the 4180.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.36%)\n",
      "\t0.8311\t = Validation score   (accuracy)\n",
      "\t6.89s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4171.72s of the 4171.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.58%)\n",
      "\t0.8303\t = Validation score   (accuracy)\n",
      "\t20.81s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 4148.63s of the 4148.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.83%)\n",
      "\t0.8306\t = Validation score   (accuracy)\n",
      "\t10.52s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 4135.99s of the 4135.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.13%)\n",
      "\t0.831\t = Validation score   (accuracy)\n",
      "\t121.87s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 4012.06s of the 4012.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.69%)\n",
      "\t0.8301\t = Validation score   (accuracy)\n",
      "\t14.27s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 430.0s of the 3995.32s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.8311\t = Validation score   (accuracy)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 725.46s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5306.5 rows/s (8095 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240622_032222\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16188, 4)\n",
      "Score: 0.8306688682060775\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "scores,oof = cross_validation(target, X, y, encoder, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "27a1f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in oof:\n",
    "    fold['true'] = fold['true'].replace(encoder)\n",
    "\n",
    "save_oof(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eafce271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240622_034550\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.9.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue May  7 09:00:52 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       11.54 GB / 22.84 GB (50.5%)\n",
      "Disk Space Avail:   12.37 GB / 95.56 GB (12.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240622_034550/ds_sub_fit/sub_fit_ho\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     LightGBMLarge_BAG_L2       0.837225   0.830503    accuracy        7.918051      27.164440  483.602638                 0.480039                1.359168          31.412802            2       True         17\n",
      "1    NeuralNetTorch_BAG_L2       0.837114   0.831128    accuracy        7.978929      26.664206  572.762059                 0.540917                0.858934         120.572223            2       True         16\n",
      "2      WeightedEnsemble_L3       0.837114   0.831601    accuracy        9.052578      28.208344  704.543140                 0.003487                0.005432           2.170193            3       True         18\n",
      "3     LightGBMLarge_BAG_L1       0.836669   0.829655    accuracy        1.382966       4.637996   22.568185                 1.382966                4.637996          22.568185            1       True          9\n",
      "4   NeuralNetFastAI_BAG_L2       0.836669   0.831086    accuracy        8.426249      27.233131  568.231066                 0.988236                1.427860         116.041230            2       True         11\n",
      "5        LightGBMXT_BAG_L2       0.836002   0.830989    accuracy        7.535931      26.164930  460.811217                 0.097919                0.359658           8.621381            2       True         12\n",
      "6           XGBoost_BAG_L1       0.835891   0.830850    accuracy        0.553138       1.835637   17.754119                 0.553138                1.835637          17.754119            1       True          7\n",
      "7      WeightedEnsemble_L2       0.835891   0.830850    accuracy        0.554569       1.841422   19.096613                 0.001432                0.005785           1.342494            2       True         10\n",
      "8          LightGBM_BAG_L2       0.835779   0.830753    accuracy        7.555681      26.235252  461.571628                 0.117669                0.429980           9.381792            2       True         13\n",
      "9          CatBoost_BAG_L2       0.835557   0.830794    accuracy        7.519937      25.916118  465.759494                 0.081925                0.110846          13.569658            2       True         14\n",
      "10          XGBoost_BAG_L2       0.834779   0.830850    accuracy        7.664433      26.353165  463.773147                 0.226421                0.547893          11.583311            2       True         15\n",
      "11         LightGBM_BAG_L1       0.834223   0.830725    accuracy        0.708170       2.037945   13.701712                 0.708170                2.037945          13.701712            1       True          5\n",
      "12       LightGBMXT_BAG_L1       0.832666   0.829919    accuracy        1.711766       6.684326   22.375486                 1.711766                6.684326          22.375486            1       True          4\n",
      "13         CatBoost_BAG_L1       0.832333   0.828765    accuracy        0.281041       0.148973   72.518427                 0.281041                0.148973          72.518427            1       True          6\n",
      "14   NeuralNetTorch_BAG_L1       0.828441   0.821204    accuracy        0.357422       0.636366  184.727986                 0.357422                0.636366         184.727986            1       True          8\n",
      "15  NeuralNetFastAI_BAG_L1       0.825995   0.822928    accuracy        1.329898       1.208706  118.393821                 1.329898                1.208706         118.393821            1       True          3\n",
      "16   KNeighborsUnif_BAG_L1       0.734823   0.731834    accuracy        0.558205       4.542234    0.072325                 0.558205                4.542234           0.072325            1       True          1\n",
      "17   KNeighborsDist_BAG_L1       0.734267   0.735198    accuracy        0.555407       4.073089    0.077775                 0.555407                4.073089           0.077775            1       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t824s\t = DyStack   runtime |\t6376s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 6376s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240622_034550\"\n",
      "Train Data Rows:    80942\n",
      "Train Data Columns: 36\n",
      "Label Column:       Target\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11355.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.23 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])   : 29 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Daytime/evening attendance', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])       : 21 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Previous qualification', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t36 features in original data used to generate 36 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 17.91 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'XT': [{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 4249.54s of the 6375.9s of remaining time.\n",
      "\t0.7334\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t5.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 4244.34s of the 6370.7s of remaining time.\n",
      "\t0.7361\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t5.47s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4238.68s of the 6365.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.67%)\n",
      "\t0.8229\t = Validation score   (accuracy)\n",
      "\t132.37s\t = Training   runtime\n",
      "\t1.3s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4104.08s of the 6230.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.14%)\n",
      "\t0.8311\t = Validation score   (accuracy)\n",
      "\t34.39s\t = Training   runtime\n",
      "\t17.8s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4064.23s of the 6190.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.10%)\n",
      "\t0.8315\t = Validation score   (accuracy)\n",
      "\t16.97s\t = Training   runtime\n",
      "\t3.19s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4044.25s of the 6170.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.16%)\n",
      "\t0.8307\t = Validation score   (accuracy)\n",
      "\t223.67s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3818.48s of the 5944.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.47%)\n",
      "\t0.833\t = Validation score   (accuracy)\n",
      "\t22.66s\t = Training   runtime\n",
      "\t3.73s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3793.44s of the 5919.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.96%)\n",
      "\t0.8222\t = Validation score   (accuracy)\n",
      "\t190.45s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 3601.03s of the 5727.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.29%)\n",
      "\t0.8307\t = Validation score   (accuracy)\n",
      "\t20.32s\t = Training   runtime\n",
      "\t4.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 424.95s of the 5703.83s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.833\t = Validation score   (accuracy)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 5702.23s of the 5702.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.45%)\n",
      "\t0.8324\t = Validation score   (accuracy)\n",
      "\t137.79s\t = Training   runtime\n",
      "\t1.57s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 5562.09s of the 5562.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.72%)\n",
      "\t0.8321\t = Validation score   (accuracy)\n",
      "\t9.99s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 5549.78s of the 5549.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.62%)\n",
      "\t0.8329\t = Validation score   (accuracy)\n",
      "\t10.6s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 5536.73s of the 5536.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.73%)\n",
      "\t0.8322\t = Validation score   (accuracy)\n",
      "\t16.62s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 5517.93s of the 5517.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=2.18%)\n",
      "\t0.8327\t = Validation score   (accuracy)\n",
      "\t13.74s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 5501.93s of the 5501.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.37%)\n",
      "\t0.8323\t = Validation score   (accuracy)\n",
      "\t156.63s\t = Training   runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 5343.12s of the 5343.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.97%)\n",
      "\t0.8327\t = Validation score   (accuracy)\n",
      "\t20.37s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 570.22s of the 5320.14s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.833\t = Validation score   (accuracy)\n",
      "\t2.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1058.76s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2712.8 rows/s (10118 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240622_034550\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_Dropout</th>\n",
       "      <th>pred_Enrolled</th>\n",
       "      <th>pred_Graduate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76518</th>\n",
       "      <td>0.994802</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.002705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76519</th>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76520</th>\n",
       "      <td>0.032434</td>\n",
       "      <td>0.221852</td>\n",
       "      <td>0.745713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76521</th>\n",
       "      <td>0.250632</td>\n",
       "      <td>0.442643</td>\n",
       "      <td>0.306725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76522</th>\n",
       "      <td>0.315104</td>\n",
       "      <td>0.638861</td>\n",
       "      <td>0.046036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127525</th>\n",
       "      <td>0.853473</td>\n",
       "      <td>0.043565</td>\n",
       "      <td>0.102961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127526</th>\n",
       "      <td>0.986771</td>\n",
       "      <td>0.012971</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127527</th>\n",
       "      <td>0.977890</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.009728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127528</th>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.098007</td>\n",
       "      <td>0.017347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127529</th>\n",
       "      <td>0.977373</td>\n",
       "      <td>0.009570</td>\n",
       "      <td>0.013057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51012 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_Dropout  pred_Enrolled  pred_Graduate\n",
       "id                                                \n",
       "76518       0.994802       0.002493       0.002705\n",
       "76519       0.005714       0.013154       0.981132\n",
       "76520       0.032434       0.221852       0.745713\n",
       "76521       0.250632       0.442643       0.306725\n",
       "76522       0.315104       0.638861       0.046036\n",
       "...              ...            ...            ...\n",
       "127525      0.853473       0.043565       0.102961\n",
       "127526      0.986771       0.012971       0.000258\n",
       "127527      0.977890       0.012382       0.009728\n",
       "127528      0.884646       0.098007       0.017347\n",
       "127529      0.977373       0.009570       0.013057\n",
       "\n",
       "[51012 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test[initial_features]\n",
    "\n",
    "predict_test(target, X, y, X_test, encoder, hyperparameters)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8710574,
     "sourceId": 73290,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10900.250809,
   "end_time": "2024-06-19T03:55:02.217184",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-19T00:53:21.966375",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
