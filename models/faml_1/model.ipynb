{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flaml in /home/rafael/anaconda3/envs/penidoEnv/lib/python3.9/site-packages (2.1.2)\n",
      "Requirement already satisfied: NumPy>=1.17 in /home/rafael/anaconda3/envs/penidoEnv/lib/python3.9/site-packages (from flaml) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/anaconda3/envs/penidoEnv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from flaml import AutoML\n",
    "\n",
    "SEED = 42 # Muito importante manter a SEED igual em todos os modelos para garantir a consistência dos dados no ensemble\n",
    "FOLDS = 5 # Muito importante manter o mesmo número de FOLDS em todos os modelos para garantir a consistência dos dados no ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sintetico = pd.read_csv('../../src/train/train.csv', index_col='id')\n",
    "original = pd.read_csv('../../src/train/original.csv')\n",
    "test = pd.read_csv('../../src/test/test.csv', index_col='id')\n",
    "\n",
    "train = pd.concat([sintetico, original], ignore_index=True)\n",
    "\n",
    "initial_features = list(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, X, y, encoder, scoring=accuracy_score):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    scores = []\n",
    "    out_of_fold = []\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {i + 1}\")\n",
    "        \n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "\n",
    "        X_val = X.iloc[val_index]\n",
    "        y_val = y.iloc[val_index]\n",
    "        \n",
    "        \n",
    "        model.fit(X_train, y_train, task=\"classification\",metric='roc_auc_ovo',time_budget=3600*3)\n",
    "\n",
    "        probabilidades = model.predict_proba(X_val)\n",
    "\n",
    "        # Recuperar a predição final a partir das probabilidades\n",
    "        indices_predicoes = np.argmax(probabilidades, axis=1)\n",
    "        classes_preditas = model.classes_[indices_predicoes]\n",
    "\n",
    "        score = scoring(y_val, classes_preditas)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "        true_label = pd.Series(y_val.values, name='true')\n",
    "\n",
    "        pred_label_df = pd.DataFrame(probabilidades)\n",
    "\n",
    "        oof_pred = pd.concat([pred_label_df, true_label], axis=1, ignore_index=True)\n",
    "        oof_pred.columns = [f'pred_{encoder[model.classes_[0]]}', f'pred_{encoder[model.classes_[1]]}', f'pred_{encoder[model.classes_[2]]}', 'true']\n",
    "\n",
    "        out_of_fold.append(oof_pred)\n",
    "\n",
    "    print(f\"Score: {np.mean(scores)}\")\n",
    "    \n",
    "    return scores, out_of_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(model, X_train, y_train, X_test, encoder):\n",
    "\n",
    "    model.fit(X_train, y_train, task='classification', estimator_list=['xgb_limitdepth'], metric='roc_auc_ovo',time_budget=3600*3)\n",
    "\n",
    "    print('Best ML leaner:', model.best_estimator)\n",
    "    print('Best hyperparmeter config:', model.best_config)\n",
    "    print('Best roc_auc_ovo  on validation data: {0:.4g}'.format(1-model.best_loss))\n",
    "\n",
    "    probabilidades = model.predict_proba(X_test)\n",
    "    pred_label_df = pd.DataFrame(probabilidades)\n",
    "\n",
    "    pred_label_df.columns = [f'pred_{encoder[model.classes_[0]]}', f'pred_{encoder[model.classes_[1]]}', f'pred_{encoder[model.classes_[2]]}']\n",
    "\n",
    "    os.makedirs('test', exist_ok=True)\n",
    "\n",
    "    pred_label_df.to_csv(f'test/test_pred.csv', index=False)\n",
    "\n",
    "    return pred_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_oof(oof):\n",
    "\n",
    "    os.makedirs('oof', exist_ok=True)\n",
    "\n",
    "    for i, fold in enumerate(oof):\n",
    "        fold.to_csv(f'oof/fold_{i+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('object')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Maritalstatus</th>\n",
       "      <th>Applicationmode</th>\n",
       "      <th>Applicationorder</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytimeeveningattendance</th>\n",
       "      <th>Previousqualification</th>\n",
       "      <th>Previousqualificationgrade</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mothersqualification</th>\n",
       "      <th>Fathersqualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricularunits2ndsemcredited</th>\n",
       "      <th>Curricularunits2ndsemenrolled</th>\n",
       "      <th>Curricularunits2ndsemevaluations</th>\n",
       "      <th>Curricularunits2ndsemapproved</th>\n",
       "      <th>Curricularunits2ndsemgrade</th>\n",
       "      <th>Curricularunits2ndsemwithoutevaluations</th>\n",
       "      <th>Unemploymentrate</th>\n",
       "      <th>Inflationrate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Maritalstatus  Applicationmode  Applicationorder  Course  \\\n",
       "0              1                1                 1    9238   \n",
       "1              1               17                 1    9238   \n",
       "2              1               17                 2    9254   \n",
       "3              1                1                 3    9500   \n",
       "4              1                1                 2    9500   \n",
       "\n",
       "   Daytimeeveningattendance  Previousqualification  \\\n",
       "0                         1                      1   \n",
       "1                         1                      1   \n",
       "2                         1                      1   \n",
       "3                         1                      1   \n",
       "4                         1                      1   \n",
       "\n",
       "   Previousqualificationgrade  Nacionality  Mothersqualification  \\\n",
       "0                       126.0            1                     1   \n",
       "1                       125.0            1                    19   \n",
       "2                       137.0            1                     3   \n",
       "3                       131.0            1                    19   \n",
       "4                       132.0            1                    19   \n",
       "\n",
       "   Fathersqualification  ...  Curricularunits2ndsemcredited  \\\n",
       "0                    19  ...                              0   \n",
       "1                    19  ...                              0   \n",
       "2                    19  ...                              0   \n",
       "3                     3  ...                              0   \n",
       "4                    37  ...                              0   \n",
       "\n",
       "   Curricularunits2ndsemenrolled  Curricularunits2ndsemevaluations  \\\n",
       "0                              6                                 7   \n",
       "1                              6                                 9   \n",
       "2                              6                                 0   \n",
       "3                              8                                11   \n",
       "4                              7                                12   \n",
       "\n",
       "   Curricularunits2ndsemapproved  Curricularunits2ndsemgrade  \\\n",
       "0                              6                   12.428571   \n",
       "1                              0                    0.000000   \n",
       "2                              0                    0.000000   \n",
       "3                              7                   12.820000   \n",
       "4                              6                   12.933333   \n",
       "\n",
       "   Curricularunits2ndsemwithoutevaluations  Unemploymentrate  Inflationrate  \\\n",
       "0                                        0              11.1            0.6   \n",
       "1                                        0              11.1            0.6   \n",
       "2                                        0              16.2            0.3   \n",
       "3                                        0              11.1            0.6   \n",
       "4                                        0               7.6            2.6   \n",
       "\n",
       "    GDP    Target  \n",
       "0  2.02  Graduate  \n",
       "1  2.02   Dropout  \n",
       "2 -0.92   Dropout  \n",
       "3  2.02  Enrolled  \n",
       "4  0.32  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 22.85 MB\n",
      "Memory usage after optimization is: 4.17 MB\n",
      "Decreased by 81.8%\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80942 entries, 0 to 80941\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   Maritalstatus                            80942 non-null  int8   \n",
      " 1   Applicationmode                          80942 non-null  int8   \n",
      " 2   Applicationorder                         80942 non-null  int8   \n",
      " 3   Course                                   80942 non-null  int16  \n",
      " 4   Daytimeeveningattendance                 80942 non-null  int8   \n",
      " 5   Previousqualification                    80942 non-null  int8   \n",
      " 6   Previousqualificationgrade               80942 non-null  float16\n",
      " 7   Nacionality                              80942 non-null  int8   \n",
      " 8   Mothersqualification                     80942 non-null  int8   \n",
      " 9   Fathersqualification                     80942 non-null  int8   \n",
      " 10  Mothersoccupation                        80942 non-null  int16  \n",
      " 11  Fathersoccupation                        80942 non-null  int16  \n",
      " 12  Admissiongrade                           80942 non-null  float16\n",
      " 13  Displaced                                80942 non-null  int8   \n",
      " 14  Educationalspecialneeds                  80942 non-null  int8   \n",
      " 15  Debtor                                   80942 non-null  int8   \n",
      " 16  Tuitionfeesuptodate                      80942 non-null  int8   \n",
      " 17  Gender                                   80942 non-null  int8   \n",
      " 18  Scholarshipholder                        80942 non-null  int8   \n",
      " 19  Ageatenrollment                          80942 non-null  int8   \n",
      " 20  International                            80942 non-null  int8   \n",
      " 21  Curricularunits1stsemcredited            80942 non-null  int8   \n",
      " 22  Curricularunits1stsemenrolled            80942 non-null  int8   \n",
      " 23  Curricularunits1stsemevaluations         80942 non-null  int8   \n",
      " 24  Curricularunits1stsemapproved            80942 non-null  int8   \n",
      " 25  Curricularunits1stsemgrade               80942 non-null  float16\n",
      " 26  Curricularunits1stsemwithoutevaluations  80942 non-null  int8   \n",
      " 27  Curricularunits2ndsemcredited            80942 non-null  int8   \n",
      " 28  Curricularunits2ndsemenrolled            80942 non-null  int8   \n",
      " 29  Curricularunits2ndsemevaluations         80942 non-null  int8   \n",
      " 30  Curricularunits2ndsemapproved            80942 non-null  int8   \n",
      " 31  Curricularunits2ndsemgrade               80942 non-null  float16\n",
      " 32  Curricularunits2ndsemwithoutevaluations  80942 non-null  int8   \n",
      " 33  Unemploymentrate                         80942 non-null  float16\n",
      " 34  Inflationrate                            80942 non-null  float16\n",
      " 35  GDP                                      80942 non-null  float16\n",
      " 36  Target                                   80942 non-null  object \n",
      "dtypes: float16(7), int16(3), int8(26), object(1)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.pop('Target')\n",
    "X = train\n",
    "\n",
    "initial_features = list(X.columns)\n",
    "\n",
    "encoder = {\n",
    "        'Graduate':'Graduate',\n",
    "        'Enrolled':'Enrolled',\n",
    "        'Dropout':'Dropout'\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# scores,oof = cross_validation(automl, X, y, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoML' object has no attribute '_best_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/rafael/Documentos/notebooks/classification_academic_success/playground-series-s4e6/models/faml_1/model.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rafael/Documentos/notebooks/classification_academic_success/playground-series-s4e6/models/faml_1/model.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest ML leaner:\u001b[39m\u001b[39m'\u001b[39m, automl\u001b[39m.\u001b[39;49mbest_estimator)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafael/Documentos/notebooks/classification_academic_success/playground-series-s4e6/models/faml_1/model.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest hyperparmeter config:\u001b[39m\u001b[39m'\u001b[39m, automl\u001b[39m.\u001b[39mbest_config)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafael/Documentos/notebooks/classification_academic_success/playground-series-s4e6/models/faml_1/model.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest roc_auc_ovo  on validation data: \u001b[39m\u001b[39m{0:.4g}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mautoml\u001b[39m.\u001b[39mbest_loss))\n",
      "File \u001b[0;32m~/anaconda3/envs/penidoEnv/lib/python3.9/site-packages/flaml/automl/automl.py:417\u001b[0m, in \u001b[0;36mAutoML.best_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbest_estimator\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    416\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A string indicating the best estimator found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_best_estimator\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoML' object has no attribute '_best_estimator'"
     ]
    }
   ],
   "source": [
    "print('Best ML leaner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best roc_auc_ovo  on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in oof:\n",
    "    fold['true'] = fold['true'].replace(encoder)\n",
    "\n",
    "save_oof(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8338995614306011,\n",
       " 0.832417073321391,\n",
       " 0.8320978502594515,\n",
       " 0.8322831727205338,\n",
       " 0.8340128490239683]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2.63 MB\n",
      "Memory usage after optimization is: 2.63 MB\n",
      "Decreased by 0.0%\n",
      "[flaml.automl.logger: 06-16 17:10:20] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 06-16 17:10:20] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 06-16 17:10:20] {1789} INFO - Minimizing error metric: 1-roc_auc_ovo\n",
      "[flaml.automl.logger: 06-16 17:10:20] {1901} INFO - List of ML learners in AutoML Run: ['xgb_limitdepth']\n",
      "[flaml.automl.logger: 06-16 17:10:20] {2219} INFO - iteration 0, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:21] {2345} INFO - Estimated sufficient time budget=13401s. Estimated necessary time budget=13s.\n",
      "[flaml.automl.logger: 06-16 17:10:21] {2392} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.0807,\tbest estimator xgb_limitdepth's best error=0.0807\n",
      "[flaml.automl.logger: 06-16 17:10:21] {2219} INFO - iteration 1, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:22] {2392} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.0807,\tbest estimator xgb_limitdepth's best error=0.0807\n",
      "[flaml.automl.logger: 06-16 17:10:22] {2219} INFO - iteration 2, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:23] {2392} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.0770,\tbest estimator xgb_limitdepth's best error=0.0770\n",
      "[flaml.automl.logger: 06-16 17:10:23] {2219} INFO - iteration 3, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:24] {2392} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.0770,\tbest estimator xgb_limitdepth's best error=0.0770\n",
      "[flaml.automl.logger: 06-16 17:10:24] {2219} INFO - iteration 4, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:26] {2392} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.0770,\tbest estimator xgb_limitdepth's best error=0.0770\n",
      "[flaml.automl.logger: 06-16 17:10:26] {2219} INFO - iteration 5, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:26] {2392} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.0770,\tbest estimator xgb_limitdepth's best error=0.0770\n",
      "[flaml.automl.logger: 06-16 17:10:26] {2219} INFO - iteration 6, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:29] {2392} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.0770,\tbest estimator xgb_limitdepth's best error=0.0770\n",
      "[flaml.automl.logger: 06-16 17:10:29] {2219} INFO - iteration 7, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:30] {2392} INFO -  at 10.9s,\testimator xgb_limitdepth's best error=0.0758,\tbest estimator xgb_limitdepth's best error=0.0758\n",
      "[flaml.automl.logger: 06-16 17:10:30] {2219} INFO - iteration 8, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:31] {2392} INFO -  at 11.9s,\testimator xgb_limitdepth's best error=0.0758,\tbest estimator xgb_limitdepth's best error=0.0758\n",
      "[flaml.automl.logger: 06-16 17:10:31] {2219} INFO - iteration 9, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:33] {2392} INFO -  at 13.6s,\testimator xgb_limitdepth's best error=0.0758,\tbest estimator xgb_limitdepth's best error=0.0758\n",
      "[flaml.automl.logger: 06-16 17:10:33] {2219} INFO - iteration 10, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:34] {2392} INFO -  at 15.0s,\testimator xgb_limitdepth's best error=0.0758,\tbest estimator xgb_limitdepth's best error=0.0758\n",
      "[flaml.automl.logger: 06-16 17:10:34] {2219} INFO - iteration 11, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:36] {2392} INFO -  at 16.6s,\testimator xgb_limitdepth's best error=0.0758,\tbest estimator xgb_limitdepth's best error=0.0758\n",
      "[flaml.automl.logger: 06-16 17:10:36] {2219} INFO - iteration 12, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:39] {2392} INFO -  at 20.1s,\testimator xgb_limitdepth's best error=0.0750,\tbest estimator xgb_limitdepth's best error=0.0750\n",
      "[flaml.automl.logger: 06-16 17:10:39] {2219} INFO - iteration 13, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:41] {2392} INFO -  at 21.5s,\testimator xgb_limitdepth's best error=0.0750,\tbest estimator xgb_limitdepth's best error=0.0750\n",
      "[flaml.automl.logger: 06-16 17:10:41] {2219} INFO - iteration 14, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:49] {2392} INFO -  at 29.8s,\testimator xgb_limitdepth's best error=0.0722,\tbest estimator xgb_limitdepth's best error=0.0722\n",
      "[flaml.automl.logger: 06-16 17:10:49] {2219} INFO - iteration 15, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:10:53] {2392} INFO -  at 34.1s,\testimator xgb_limitdepth's best error=0.0722,\tbest estimator xgb_limitdepth's best error=0.0722\n",
      "[flaml.automl.logger: 06-16 17:10:53] {2219} INFO - iteration 16, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:11:05] {2392} INFO -  at 45.9s,\testimator xgb_limitdepth's best error=0.0722,\tbest estimator xgb_limitdepth's best error=0.0722\n",
      "[flaml.automl.logger: 06-16 17:11:05] {2219} INFO - iteration 17, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:11:08] {2392} INFO -  at 48.4s,\testimator xgb_limitdepth's best error=0.0722,\tbest estimator xgb_limitdepth's best error=0.0722\n",
      "[flaml.automl.logger: 06-16 17:11:08] {2219} INFO - iteration 18, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:11:23] {2392} INFO -  at 63.5s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:11:23] {2219} INFO - iteration 19, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:11:27] {2392} INFO -  at 67.8s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:11:27] {2219} INFO - iteration 20, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:12:24] {2392} INFO -  at 124.5s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:12:24] {2219} INFO - iteration 21, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:12:35] {2392} INFO -  at 136.0s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:12:35] {2219} INFO - iteration 22, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:12:57] {2392} INFO -  at 157.7s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:12:57] {2219} INFO - iteration 23, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:13:06] {2392} INFO -  at 166.7s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:13:06] {2219} INFO - iteration 24, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:13:38] {2392} INFO -  at 198.2s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:13:38] {2219} INFO - iteration 25, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:13:41] {2392} INFO -  at 201.8s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:13:41] {2219} INFO - iteration 26, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:14:55] {2392} INFO -  at 275.8s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:14:55] {2219} INFO - iteration 27, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:15:06] {2392} INFO -  at 287.0s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:15:06] {2219} INFO - iteration 28, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:15:29] {2392} INFO -  at 309.5s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:15:29] {2219} INFO - iteration 29, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:15:32] {2392} INFO -  at 313.0s,\testimator xgb_limitdepth's best error=0.0715,\tbest estimator xgb_limitdepth's best error=0.0715\n",
      "[flaml.automl.logger: 06-16 17:15:32] {2219} INFO - iteration 30, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:16:29] {2392} INFO -  at 370.2s,\testimator xgb_limitdepth's best error=0.0714,\tbest estimator xgb_limitdepth's best error=0.0714\n",
      "[flaml.automl.logger: 06-16 17:16:29] {2219} INFO - iteration 31, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:17:21] {2392} INFO -  at 421.6s,\testimator xgb_limitdepth's best error=0.0714,\tbest estimator xgb_limitdepth's best error=0.0714\n",
      "[flaml.automl.logger: 06-16 17:17:21] {2219} INFO - iteration 32, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:18:07] {2392} INFO -  at 468.0s,\testimator xgb_limitdepth's best error=0.0712,\tbest estimator xgb_limitdepth's best error=0.0712\n",
      "[flaml.automl.logger: 06-16 17:18:07] {2219} INFO - iteration 33, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:19:34] {2392} INFO -  at 555.2s,\testimator xgb_limitdepth's best error=0.0711,\tbest estimator xgb_limitdepth's best error=0.0711\n",
      "[flaml.automl.logger: 06-16 17:19:34] {2219} INFO - iteration 34, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:20:21] {2392} INFO -  at 601.3s,\testimator xgb_limitdepth's best error=0.0711,\tbest estimator xgb_limitdepth's best error=0.0711\n",
      "[flaml.automl.logger: 06-16 17:20:21] {2219} INFO - iteration 35, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:29:52] {2392} INFO -  at 1173.0s,\testimator xgb_limitdepth's best error=0.0711,\tbest estimator xgb_limitdepth's best error=0.0711\n",
      "[flaml.automl.logger: 06-16 17:29:52] {2219} INFO - iteration 36, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:30:07] {2392} INFO -  at 1187.9s,\testimator xgb_limitdepth's best error=0.0711,\tbest estimator xgb_limitdepth's best error=0.0711\n",
      "[flaml.automl.logger: 06-16 17:30:07] {2219} INFO - iteration 37, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:31:18] {2392} INFO -  at 1258.3s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:31:18] {2219} INFO - iteration 38, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:32:46] {2392} INFO -  at 1346.9s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:32:46] {2219} INFO - iteration 39, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:34:30] {2392} INFO -  at 1451.1s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:34:30] {2219} INFO - iteration 40, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:35:21] {2392} INFO -  at 1501.5s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:35:21] {2219} INFO - iteration 41, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:35:50] {2392} INFO -  at 1530.9s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:35:50] {2219} INFO - iteration 42, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:38:42] {2392} INFO -  at 1702.9s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:38:42] {2219} INFO - iteration 43, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:40:15] {2392} INFO -  at 1795.5s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:40:15] {2219} INFO - iteration 44, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:41:13] {2392} INFO -  at 1853.2s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:41:13] {2219} INFO - iteration 45, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:43:56] {2392} INFO -  at 2017.1s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:43:56] {2219} INFO - iteration 46, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:44:27] {2392} INFO -  at 2047.5s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:44:27] {2219} INFO - iteration 47, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:45:10] {2392} INFO -  at 2090.6s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:45:10] {2219} INFO - iteration 48, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:47:19] {2392} INFO -  at 2220.1s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:47:19] {2219} INFO - iteration 49, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:49:56] {2392} INFO -  at 2377.0s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:49:56] {2219} INFO - iteration 50, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:50:34] {2392} INFO -  at 2414.6s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:50:34] {2219} INFO - iteration 51, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:53:17] {2392} INFO -  at 2577.3s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:53:17] {2219} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:53:55] {2392} INFO -  at 2615.9s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:53:55] {2219} INFO - iteration 53, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:56:14] {2392} INFO -  at 2754.8s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:56:14] {2219} INFO - iteration 54, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:56:57] {2392} INFO -  at 2797.3s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:56:57] {2219} INFO - iteration 55, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:58:20] {2392} INFO -  at 2880.3s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:58:20] {2219} INFO - iteration 56, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 17:59:24] {2392} INFO -  at 2945.1s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 17:59:24] {2219} INFO - iteration 57, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:02:42] {2392} INFO -  at 3142.4s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:02:42] {2219} INFO - iteration 58, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:03:11] {2392} INFO -  at 3171.7s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:03:11] {2219} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:03:59] {2392} INFO -  at 3219.6s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:03:59] {2219} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:05:43] {2392} INFO -  at 3323.3s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:05:43] {2219} INFO - iteration 61, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:08:38] {2392} INFO -  at 3498.5s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:08:38] {2219} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:09:11] {2392} INFO -  at 3531.4s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:09:11] {2219} INFO - iteration 63, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:10:29] {2392} INFO -  at 3609.3s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:10:29] {2219} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:11:38] {2392} INFO -  at 3678.3s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:11:38] {2219} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:11:52] {2392} INFO -  at 3693.2s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:11:52] {2219} INFO - iteration 66, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:18:05] {2392} INFO -  at 4065.8s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:18:05] {2219} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:19:41] {2392} INFO -  at 4161.4s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:19:41] {2219} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:20:52] {2392} INFO -  at 4232.7s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:20:52] {2219} INFO - iteration 69, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:24:35] {2392} INFO -  at 4455.9s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:24:35] {2219} INFO - iteration 70, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:25:21] {2392} INFO -  at 4501.9s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:25:21] {2219} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:27:54] {2392} INFO -  at 4655.0s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:27:54] {2219} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:28:53] {2392} INFO -  at 4713.8s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:28:53] {2219} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:30:50] {2392} INFO -  at 4830.9s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:30:50] {2219} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:32:09] {2392} INFO -  at 4909.5s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:32:09] {2219} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:34:22] {2392} INFO -  at 5042.3s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:34:22] {2219} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:35:41] {2392} INFO -  at 5122.2s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:35:41] {2219} INFO - iteration 77, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:38:37] {2392} INFO -  at 5297.4s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:38:37] {2219} INFO - iteration 78, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:39:33] {2392} INFO -  at 5353.8s,\testimator xgb_limitdepth's best error=0.0708,\tbest estimator xgb_limitdepth's best error=0.0708\n",
      "[flaml.automl.logger: 06-16 18:39:33] {2219} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:42:28] {2392} INFO -  at 5528.9s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 18:42:28] {2219} INFO - iteration 80, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:43:59] {2392} INFO -  at 5619.4s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 18:43:59] {2219} INFO - iteration 81, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:49:57] {2392} INFO -  at 5977.8s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 18:49:57] {2219} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:55:14] {2392} INFO -  at 6294.3s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 18:55:14] {2219} INFO - iteration 83, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:56:53] {2392} INFO -  at 6393.8s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 18:56:53] {2219} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 18:59:11] {2392} INFO -  at 6532.0s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 18:59:11] {2219} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:03:32] {2392} INFO -  at 6793.2s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:03:32] {2219} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:09:14] {2392} INFO -  at 7134.9s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:09:14] {2219} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:10:51] {2392} INFO -  at 7231.6s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:10:51] {2219} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:16:29] {2392} INFO -  at 7569.9s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:16:29] {2219} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:18:01] {2392} INFO -  at 7661.6s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:18:01] {2219} INFO - iteration 90, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:21:07] {2392} INFO -  at 7847.7s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:21:07] {2219} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:23:56] {2392} INFO -  at 8017.0s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:23:56] {2219} INFO - iteration 92, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:25:45] {2392} INFO -  at 8125.3s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:25:45] {2219} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:30:37] {2392} INFO -  at 8417.4s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:30:37] {2219} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:39:16] {2392} INFO -  at 8937.0s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:39:16] {2219} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:40:19] {2392} INFO -  at 9000.0s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:40:19] {2219} INFO - iteration 96, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:42:02] {2392} INFO -  at 9102.9s,\testimator xgb_limitdepth's best error=0.0706,\tbest estimator xgb_limitdepth's best error=0.0706\n",
      "[flaml.automl.logger: 06-16 19:42:02] {2219} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 19:46:58] {2392} INFO -  at 9399.0s,\testimator xgb_limitdepth's best error=0.0700,\tbest estimator xgb_limitdepth's best error=0.0700\n",
      "[flaml.automl.logger: 06-16 19:46:58] {2219} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 20:00:39] {2392} INFO -  at 10219.9s,\testimator xgb_limitdepth's best error=0.0700,\tbest estimator xgb_limitdepth's best error=0.0700\n",
      "[flaml.automl.logger: 06-16 20:00:39] {2219} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 20:02:38] {2392} INFO -  at 10339.0s,\testimator xgb_limitdepth's best error=0.0700,\tbest estimator xgb_limitdepth's best error=0.0700\n",
      "[flaml.automl.logger: 06-16 20:02:38] {2219} INFO - iteration 100, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 06-16 20:10:39] {2392} INFO -  at 10819.8s,\testimator xgb_limitdepth's best error=0.0700,\tbest estimator xgb_limitdepth's best error=0.0700\n",
      "[flaml.automl.logger: 06-16 20:11:51] {2628} INFO - retrain xgb_limitdepth for 72.3s\n",
      "[flaml.automl.logger: 06-16 20:11:51] {2631} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=0.9685549403358893, colsample_bynode=None,\n",
      "              colsample_bytree=0.21642415803269258, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=None,\n",
      "              grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.004452940692603317,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=0.8817413282847583, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=7097,\n",
      "              n_jobs=-1, num_parallel_tree=None, objective='multi:softprob', ...)\n",
      "[flaml.automl.logger: 06-16 20:11:51] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-16 20:11:51] {1932} INFO - Time taken to find the best model: 9399.023427724838\n",
      "Best ML leaner: xgb_limitdepth\n",
      "Best hyperparmeter config: {'n_estimators': 7097, 'max_depth': 7, 'min_child_weight': 0.8817413282847583, 'learning_rate': 0.004452940692603317, 'subsample': 0.7746129099296352, 'colsample_bylevel': 0.9685549403358893, 'colsample_bytree': 0.21642415803269258, 'reg_alpha': 0.018438279435087784, 'reg_lambda': 0.06696260390023717}\n",
      "Best roc_auc_ovo  on validation data: 0.93\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_Dropout</th>\n",
       "      <th>pred_Enrolled</th>\n",
       "      <th>pred_Graduate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995140</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.011303</td>\n",
       "      <td>0.984732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039133</td>\n",
       "      <td>0.241275</td>\n",
       "      <td>0.719592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.190587</td>\n",
       "      <td>0.374050</td>\n",
       "      <td>0.435363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.253132</td>\n",
       "      <td>0.700345</td>\n",
       "      <td>0.046523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51007</th>\n",
       "      <td>0.872543</td>\n",
       "      <td>0.050366</td>\n",
       "      <td>0.077091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51008</th>\n",
       "      <td>0.986633</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51009</th>\n",
       "      <td>0.976407</td>\n",
       "      <td>0.017002</td>\n",
       "      <td>0.006591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51010</th>\n",
       "      <td>0.866007</td>\n",
       "      <td>0.118625</td>\n",
       "      <td>0.015369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51011</th>\n",
       "      <td>0.983312</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>0.009979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51012 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred_Dropout  pred_Enrolled  pred_Graduate\n",
       "0          0.995140       0.002671       0.002188\n",
       "1          0.003964       0.011303       0.984732\n",
       "2          0.039133       0.241275       0.719592\n",
       "3          0.190587       0.374050       0.435363\n",
       "4          0.253132       0.700345       0.046523\n",
       "...             ...            ...            ...\n",
       "51007      0.872543       0.050366       0.077091\n",
       "51008      0.986633       0.013246       0.000121\n",
       "51009      0.976407       0.017002       0.006591\n",
       "51010      0.866007       0.118625       0.015369\n",
       "51011      0.983312       0.006709       0.009979\n",
       "\n",
       "[51012 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "test = reduce_mem_usage(test)\n",
    "X_test = test[initial_features]\n",
    "\n",
    "automl = AutoML()\n",
    "\n",
    "predict_test(automl, X, y, X_test, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penidoEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
